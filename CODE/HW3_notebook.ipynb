{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU46SgXILFcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp \"drive/My Drive/Colab Notebooks/HW3/main.py\"\n",
        "\n",
        "#!cp --help\n",
        "\n",
        "#!cd \"drive/My Drive/Colab Notebooks/HW3/\"\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive/')\n",
        "\n",
        "#import sys\n",
        "#sys.path.append('/content/gdrive/My Drive/Colab Notebooks/HW3/')\n",
        "\n",
        "#import main\n",
        "#import drive.My Drive.Colab Notebooks/HW3/main.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUWMvF4i_wPu",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLWXZdT5_tvD",
        "colab_type": "code",
        "outputId": "90fd325c-6833-4723-fc60-4b537561fb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework3-PACS'):\n",
        "\t!git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "\n",
        "# Clone github repository with data\n",
        "if not os.path.isdir('./models'):\n",
        "  !git clone https://github.com/gabrieletiboni/DANN-on-PACS-dataset.git\n",
        "  !cp -r \"/content/DANN-on-PACS-dataset/CODE/functions\" \"/content/\"\n",
        "  !cp -r \"/content/DANN-on-PACS-dataset/CODE/models\" \"/content/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10032, done.\u001b[K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqURuXj-_3aV",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_EI1x5sQJjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install 'torch==1.3.1'\n",
        "# !pip3 install 'torchvision==0.5.0'\n",
        "# !pip3 install 'Pillow-SIMD'\n",
        "# !pip3 install 'tqdm'\n",
        "\n",
        "import logging\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "#from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from models.AlexNetDANN import alexnetDANN\n",
        "from functions.functions import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzcjGTZlAlwW",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x93idUtx_7_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = 7\n",
        "DIR_RUNS = '02 VERE PROVE/'\n",
        "\n",
        "# -----------------\n",
        "ID_RUN = '9'\n",
        "RUN_NUMBER = '1'\n",
        "\n",
        "BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "\t\t\t\t\t\t\t\t\t\t # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 1e-2            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 60      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 30        # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "ALPHA = 0.1\t\t\t\t\t   # Multiplicative factor for the backpropogating gradient from the domain_classifier\n",
        "\n",
        "DOMAIN_ADAPTATION = False\n",
        "EVAL_ACCURACY_ON_TRAINING = True\n",
        "EVAL_LOSS_AND_ACCURACY_ON_VALIDATION = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oWLgxqpAoNt",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGlxDiVtAOc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEANS, STDS = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([#transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "\t\t\t\t\t\t\t\t\ttransforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t # Remember this when applying different transformations, otherwise you get an error\n",
        "\t\t\t\t\t\t\t\t\ttransforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "\t\t\t\t\t\t\t\t\ttransforms.Normalize(MEANS, STDS) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([#transforms.Resize(256),\n",
        "\t\t\t\t\t\t\t\t\ttransforms.CenterCrop(224),\n",
        "\t\t\t\t\t\t\t\t\ttransforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\ttransforms.Normalize(MEANS, STDS)\n",
        "])\n",
        "\n",
        "DATA_DIR = 'Homework3-PACS/PACS'\n",
        "\n",
        "photo_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/photo', transform=train_transform)\n",
        "art_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/art_painting', transform=train_transform)\n",
        "cartoon_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/cartoon', transform=eval_transform)\n",
        "sketch_dataset = torchvision.datasets.ImageFolder(DATA_DIR+'/sketch', transform=eval_transform)\n",
        "\n",
        "PACSdataset = [photo_dataset, art_dataset, cartoon_dataset, sketch_dataset]\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Photo Dataset: {}'.format(len(photo_dataset)))\n",
        "print('Art Dataset: {}'.format(len(art_dataset)))\n",
        "print('Cartoon Dataset: {}'.format(len(cartoon_dataset)))\n",
        "print('Sketch Dataset: {}'.format(len(sketch_dataset)))\n",
        "\n",
        "print('Classes:', photo_dataset.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf940osZA9d2",
        "colab_type": "text"
      },
      "source": [
        "**Data exploration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0QYGqqYA8xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Print some images\n",
        "# nPhotos = 4\n",
        "# for dataset in PACSdataset:\n",
        "# \tfor i in range(nPhotos):\n",
        "# \t\tindex = np.random.randint(0, len(dataset))\n",
        "# \t\timgshow(dataset[index][0])\n",
        "\n",
        "# --- Explore class distributions across domains\n",
        "# labels_photo = photo_dataset.targets\n",
        "# labels_art = art_dataset.targets\n",
        "# labels_cartoon = cartoon_dataset.targets\n",
        "# labels_sketch = sketch_dataset.targets\n",
        "# plotBar(labels_photo, labels_art, labels_cartoon, labels_sketch, photo_dataset.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQaN5hCQA00H",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoBCxTTJAzYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Training dataloaders\n",
        "photo_dataloader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "art_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "# --- Test datasets\n",
        "photo_test_dataloader = DataLoader(photo_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "art_test_dataloader = DataLoader(art_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "cartoon_test_dataloader = DataLoader(cartoon_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "sketch_test_dataloader = DataLoader(sketch_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "# DEBUG\n",
        "# Split train into train and val\n",
        "#train_indexes, test_indexes, _, _ = train_test_split([i for i in range(len(photo_dataset))], labels_photo, test_size=0.3, stratify=labels_photo)\n",
        "\n",
        "#train_dataset = Subset(photo_dataset, train_indexes)\n",
        "#test_dataset = Subset(photo_dataset, test_indexes)\n",
        "\n",
        "#train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIwG-N_MAvdU",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxc5Iw8EAstX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexnetDANN(pretrained=True)\n",
        "\n",
        "# --- Check that pretrined weights have been correctly copied into the domain_classifier branch as well\n",
        "#for domain_param, classifier_param in zip(list(net.classifier.parameters()), list(net.domain_classifier.parameters())):\n",
        "  #print(torch.allclose(domain_param, classifier_param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teXZa2uuAeI4",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvYIop-ZAc3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "criterion_val = nn.CrossEntropyLoss(reduction='sum') # for evaluation I don't want to avg over every minibatch\n",
        "\n",
        "# Choose parameters to optimize\n",
        "parameters_to_optimize = net.parameters()\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WTOUo3EAZsF",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WWx9dWfAWEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "current_step = 0\n",
        "losses_train = []\n",
        "losses_train_classifier = []\n",
        "losses_train_domain = []\n",
        "losses_val = []\n",
        "accuracies_val = []\n",
        "accuracies_train = []\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "  if DOMAIN_ADAPTATION:\n",
        "    len_dataloader = min(len(photo_dataloader), len(art_dataloader))\n",
        "    data_source_iter = iter(photo_dataloader)\n",
        "    data_target_iter = iter(art_dataloader)\n",
        "  else:\n",
        "    len_dataloader = len(photo_dataloader)\n",
        "    data_source_iter = iter(photo_dataloader)\n",
        "\n",
        "  i = 0\n",
        "  while i < len_dataloader:\n",
        "  #for images, labels in photo_dataloader:\n",
        "\t  # Bring data over the device of choice\n",
        "    data_source = data_source_iter.next()\n",
        "    s_images, s_labels = data_source\n",
        "\n",
        "    #print('Batch size inferred 1:', len(s_labels))\n",
        "\n",
        "    s_images = s_images.to(DEVICE)\n",
        "    s_labels = s_labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    if DOMAIN_ADAPTATION:\n",
        "      # FEED-FORWARD SOURCE TO CLASSIFIER\n",
        "      source_classifier_outputs = net(s_images, dest='classifier')\n",
        "      source_classifier_err = criterion(source_classifier_outputs, s_labels)\n",
        "\n",
        "      # FEED-FORWARD SOURCE TO DOMAIN_CLASSIFIER\n",
        "      source_domain_outputs = net(s_images, alpha=ALPHA, dest='domain_classifier')\n",
        "      source_domain_labels = torch.zeros(BATCH_SIZE).long().to(DEVICE)\n",
        "      source_domain_err = criterion(source_domain_outputs, source_domain_labels)\n",
        "\n",
        "      # FEED-FORWARD TARGET TO DOMAIN_CLASSIFIER\n",
        "      data_target = data_target_iter.next()\n",
        "      t_images, t_labels = data_target\n",
        "\n",
        "      #print('Batch size inferred 2:', len(t_labels))\n",
        "\n",
        "      t_images = t_images.to(DEVICE)\n",
        "      t_labels = t_labels.to(DEVICE)\n",
        "\n",
        "      target_domain_outputs = net(t_images, alpha=ALPHA, dest='domain_classifier')\n",
        "      target_domain_labels = torch.ones(BATCH_SIZE).long().to(DEVICE)\n",
        "      target_domain_err = criterion(target_domain_outputs, target_domain_labels)\n",
        "\n",
        "      loss = source_classifier_err + source_domain_err + target_domain_err\n",
        "\n",
        "    else:\n",
        "      # Forward pass to the network\n",
        "      outputs = net(s_images, dest='classifier')\n",
        "      # Compute loss based on output and ground truth\n",
        "      loss = criterion(outputs, s_labels)\n",
        "\n",
        "    if current_step == 0 and DOMAIN_ADAPTATION == False:\n",
        "      print('--- Initial loss on train: {}'.format(loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    i +=1\n",
        "\n",
        "\t# End of one epoch    \n",
        "  if DOMAIN_ADAPTATION:\n",
        "    print('--- Epoch {}'.format(epoch+1))\n",
        "    losses_train_classifier.append(source_classifier_err.item())\n",
        "    losses_train_domain.append((source_domain_err.item()+target_domain_err.item()))\n",
        "  else:\n",
        "    print('--- Epoch {}, Loss on train: {}'.format(epoch+1, loss.item()))\n",
        "    losses_train.append(loss.item())\n",
        "  \n",
        "  if EVAL_LOSS_AND_ACCURACY_ON_VALIDATION:\n",
        "    \n",
        "    net.train(False)\n",
        "\n",
        "    running_corrects_val = 0\n",
        "    cum_loss_val = 0\n",
        "\n",
        "    #for images_val, labels_val in tqdm(val_dataloader):\n",
        "    for images_val, labels_val in art_test_dataloader:\n",
        "      images_val = images_val.to(DEVICE)\n",
        "      labels_val = labels_val.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs_val = net(images_val, dest='classifier')\n",
        "\n",
        "      cum_loss_val += criterion_val(outputs_val, labels_val).item()\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs_val.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects_val += torch.sum(preds == labels_val.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy_val = running_corrects_val / float(len(art_dataset))\n",
        "    loss_val = cum_loss_val / float(len(art_dataset))\n",
        "\n",
        "    losses_val.append(loss_val)\n",
        "    accuracies_val.append(accuracy_val)\n",
        "    \n",
        "    print('Loss on val:', loss_val)\n",
        "    print('Accuracy on val:', accuracy_val)\n",
        "\n",
        "  if EVAL_ACCURACY_ON_TRAINING:\n",
        "    net.train(False)\n",
        "\n",
        "    running_corrects_train = 0\n",
        "\n",
        "    for images_train, labels_train in photo_test_dataloader:\n",
        "      images_train = images_train.to(DEVICE)\n",
        "      labels_train = labels_train.to(DEVICE)\n",
        "\n",
        "      # Forward Pass\n",
        "      outputs_train = net(images_train, dest='classifier')\n",
        "\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs_train.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      running_corrects_train += torch.sum(preds == labels_train.data).data.item()\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy_train = running_corrects_train / float(len(photo_dataset))\n",
        "\n",
        "    accuracies_train.append(accuracy_train)\n",
        "\n",
        "    print('Accuracy on train:', accuracy_train)\n",
        "\n",
        "\t# Step the scheduler\n",
        "  scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XidGuT7qgiT-",
        "colab_type": "text"
      },
      "source": [
        "**Debug**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM4JzdigghzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('TL:')\n",
        "print(losses_train)\n",
        "print('Classifier loss on source:')\n",
        "print(losses_train_classifier)\n",
        "print('Domain classifier loss:')\n",
        "print(losses_train_domain)\n",
        "print(losses_val)\n",
        "print(accuracies_train)\n",
        "print(accuracies_val)\n",
        "print()\n",
        "\n",
        "if not os.path.isdir(DIR_RUNS):\n",
        "  os.makedirs(DIR_RUNS)\n",
        "\n",
        "with open(DIR_RUNS+ID_RUN+' - values.txt', 'a+') as f:\n",
        "  print('TL:', file=f)\n",
        "  print(losses_train, file=f)\n",
        "  print('Classifier loss on source:', file=f)\n",
        "  print(losses_train_classifier, file=f)\n",
        "  print('Domain classifier loss:', file=f)\n",
        "  print(losses_train_domain, file=f)\n",
        "  print(losses_val, file=f)\n",
        "  print(accuracies_train, file=f)\n",
        "  print(accuracies_val, file=f)\n",
        "  print('', file=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CmMG_lsFlqS",
        "colab_type": "text"
      },
      "source": [
        "**Plot results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-sTiFFSFnto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,5))\n",
        "\n",
        "epochs = [i for i in range(1, NUM_EPOCHS+1)]\n",
        "if DOMAIN_ADAPTATION:\n",
        "  ax.plot(epochs, losses_train_classifier, linestyle='-', marker='o', label='Training loss on label classifier')\n",
        "  ax.plot(epochs, losses_train_domain, linestyle='-', marker='o', label='Training loss on domain classifier')\n",
        "  ax.plot(epochs, losses_val, linestyle='-', marker='o', label='Test loss on label classifier')\n",
        "else:\n",
        "  ax.plot(epochs, losses_train, linestyle='-', marker='*', label='Training loss')\n",
        "  ax.plot(epochs, losses_val, linestyle='-', marker='o', label='Test loss')\n",
        "\n",
        "ax.set_xlabel('Epochs', labelpad=12, fontweight='bold')\n",
        "ax.set_ylabel('Cross Entropy Loss', labelpad=12, rotation=90, fontweight='bold')\n",
        "\n",
        "ax.set_title('Loss during gradient descent', pad=20, fontweight='bold')\n",
        "\n",
        "ax.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "fig.savefig(DIR_RUNS+ID_RUN+' '+str(RUN_NUMBER)+' - loss.png')\n",
        "\n",
        "# Plot accuracies\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,5))\n",
        "\n",
        "epochs = [i for i in range(1, NUM_EPOCHS+1)]\n",
        "ax.plot(epochs, accuracies_train, color='#7B1FA2', linestyle='-', marker='o', label='Training accuracy')\n",
        "ax.plot(epochs, accuracies_val, color='#FFC107', linestyle='-', marker='o', label='Test accuracy')\n",
        "\n",
        "ax.set_xlabel('Epochs', labelpad=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy', labelpad=12, rotation=90, fontweight='bold')\n",
        "\n",
        "ax.set_title('Accuracy during gradient descent', pad=20, fontweight='bold')\n",
        "\n",
        "ax.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "fig.savefig(DIR_RUNS+ID_RUN+' '+str(RUN_NUMBER)+' - accuracy.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skw-WNPsARI_",
        "colab_type": "text"
      },
      "source": [
        "**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9GcGajkAQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_test_dataloader):\n",
        "\timages = images.to(DEVICE)\n",
        "\tlabels = labels.to(DEVICE)\n",
        "\n",
        "\t# Forward Pass\n",
        "\toutputs = net(images, dest='classifier')\n",
        "\n",
        "\t# Get predictions\n",
        "\t_, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "\t# Update Corrects\n",
        "\trunning_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENmCH6FtfPyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !zip -r \"/content/RUNS_4.zip\" \"/content/02 VERE PROVE\"\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"/content/RUNS_4.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}